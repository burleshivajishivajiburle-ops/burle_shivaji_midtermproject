{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4207e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA MINING PROJECT\n",
      "\n",
      "AVAILABLE DATASETS (from Create Data part):\n",
      "\n",
      "1. Amazon_Transactions.csv\n",
      "2. BestBuy_Transactions.csv\n",
      "3. KMart_Transactions.csv\n",
      "4. Custom_Transactions.csv\n",
      "5. Nike_Transactions.csv\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your dataset choice (1-5):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: Nike_Transactions.csv\n",
      "Successfully loaded dataset: Nike_Transactions.csv\n",
      "Dataset contains 20 transactions\n",
      "\n",
      "Processing transaction data...\n",
      "Successfully processed 20 transactions\n",
      "\n",
      "PARAMETER CONFIGURATION:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Minimum Support (0.0 - 1.0):  0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Support set to: 0.4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Minimum Confidence (0.0 - 1.0):  0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Confidence set to: 0.4\n",
      "\n",
      "Starting analysis with Support=0.4, Confidence=0.4\n",
      "\n",
      "\n",
      "Running Brute-Force Apriori Algorithm...\n",
      "\n",
      "BRUTE-FORCE APRIORI\n",
      "\n",
      "Dry Fit V-Nick | Support: 0.45\n",
      "Hoodies | Support: 0.40\n",
      "Modern Pants | Support: 0.50\n",
      "Rash Guard | Support: 0.60\n",
      "Running Shoe | Support: 0.70\n",
      "Socks | Support: 0.65\n",
      "Sweatshirts | Support: 0.65\n",
      "Swimming Shirt | Support: 0.55\n",
      "Tech Pants | Support: 0.45\n",
      "Dry Fit V-Nick, Rash Guard | Support: 0.45\n",
      "Dry Fit V-Nick, Swimming Shirt | Support: 0.40\n",
      "Dry Fit V-Nick, Tech Pants | Support: 0.40\n",
      "Hoodies, Rash Guard | Support: 0.40\n",
      "Hoodies, Tech Pants | Support: 0.40\n",
      "Modern Pants, Running Shoe | Support: 0.45\n",
      "Modern Pants, Socks | Support: 0.45\n",
      "Modern Pants, Sweatshirts | Support: 0.50\n",
      "Rash Guard, Swimming Shirt | Support: 0.50\n",
      "Rash Guard, Tech Pants | Support: 0.45\n",
      "Running Shoe, Socks | Support: 0.55\n",
      "Running Shoe, Sweatshirts | Support: 0.55\n",
      "Socks, Sweatshirts | Support: 0.60\n",
      "Dry Fit V-Nick, Rash Guard, Swimming Shirt | Support: 0.40\n",
      "Dry Fit V-Nick, Rash Guard, Tech Pants | Support: 0.40\n",
      "Hoodies, Rash Guard, Tech Pants | Support: 0.40\n",
      "Modern Pants, Running Shoe, Socks | Support: 0.40\n",
      "Modern Pants, Running Shoe, Sweatshirts | Support: 0.45\n",
      "Modern Pants, Socks, Sweatshirts | Support: 0.45\n",
      "Running Shoe, Socks, Sweatshirts | Support: 0.50\n",
      "Modern Pants, Running Shoe, Socks, Sweatshirts | Support: 0.40\n",
      "\n",
      "Association Rules:\n",
      "Dry Fit V-Nick -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Dry Fit V-Nick (Confidence: 0.75)\n",
      "Dry Fit V-Nick -> Swimming Shirt (Confidence: 0.89)\n",
      "Swimming Shirt -> Dry Fit V-Nick (Confidence: 0.73)\n",
      "Dry Fit V-Nick -> Tech Pants (Confidence: 0.89)\n",
      "Tech Pants -> Dry Fit V-Nick (Confidence: 0.89)\n",
      "Hoodies -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Hoodies (Confidence: 0.67)\n",
      "Hoodies -> Tech Pants (Confidence: 1.00)\n",
      "Tech Pants -> Hoodies (Confidence: 0.89)\n",
      "Modern Pants -> Running Shoe (Confidence: 0.90)\n",
      "Running Shoe -> Modern Pants (Confidence: 0.64)\n",
      "Modern Pants -> Socks (Confidence: 0.90)\n",
      "Socks -> Modern Pants (Confidence: 0.69)\n",
      "Modern Pants -> Sweatshirts (Confidence: 1.00)\n",
      "Sweatshirts -> Modern Pants (Confidence: 0.77)\n",
      "Rash Guard -> Swimming Shirt (Confidence: 0.83)\n",
      "Swimming Shirt -> Rash Guard (Confidence: 0.91)\n",
      "Rash Guard -> Tech Pants (Confidence: 0.75)\n",
      "Tech Pants -> Rash Guard (Confidence: 1.00)\n",
      "Running Shoe -> Socks (Confidence: 0.79)\n",
      "Socks -> Running Shoe (Confidence: 0.85)\n",
      "Running Shoe -> Sweatshirts (Confidence: 0.79)\n",
      "Sweatshirts -> Running Shoe (Confidence: 0.85)\n",
      "Socks -> Sweatshirts (Confidence: 0.92)\n",
      "Sweatshirts -> Socks (Confidence: 0.92)\n",
      "Dry Fit V-Nick -> Swimming Shirt, Rash Guard (Confidence: 0.89)\n",
      "Rash Guard -> Swimming Shirt, Dry Fit V-Nick (Confidence: 0.67)\n",
      "Swimming Shirt -> Dry Fit V-Nick, Rash Guard (Confidence: 0.73)\n",
      "Dry Fit V-Nick, Rash Guard -> Swimming Shirt (Confidence: 0.89)\n",
      "Dry Fit V-Nick, Swimming Shirt -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard, Swimming Shirt -> Dry Fit V-Nick (Confidence: 0.80)\n",
      "Dry Fit V-Nick -> Tech Pants, Rash Guard (Confidence: 0.89)\n",
      "Rash Guard -> Dry Fit V-Nick, Tech Pants (Confidence: 0.67)\n",
      "Tech Pants -> Dry Fit V-Nick, Rash Guard (Confidence: 0.89)\n",
      "Dry Fit V-Nick, Rash Guard -> Tech Pants (Confidence: 0.89)\n",
      "Dry Fit V-Nick, Tech Pants -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard, Tech Pants -> Dry Fit V-Nick (Confidence: 0.89)\n",
      "Hoodies -> Tech Pants, Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Tech Pants, Hoodies (Confidence: 0.67)\n",
      "Tech Pants -> Hoodies, Rash Guard (Confidence: 0.89)\n",
      "Hoodies, Rash Guard -> Tech Pants (Confidence: 1.00)\n",
      "Hoodies, Tech Pants -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard, Tech Pants -> Hoodies (Confidence: 0.89)\n",
      "Modern Pants -> Socks, Running Shoe (Confidence: 0.80)\n",
      "Running Shoe -> Modern Pants, Socks (Confidence: 0.57)\n",
      "Socks -> Modern Pants, Running Shoe (Confidence: 0.62)\n",
      "Modern Pants, Running Shoe -> Socks (Confidence: 0.89)\n",
      "Modern Pants, Socks -> Running Shoe (Confidence: 0.89)\n",
      "Running Shoe, Socks -> Modern Pants (Confidence: 0.73)\n",
      "Modern Pants -> Sweatshirts, Running Shoe (Confidence: 0.90)\n",
      "Running Shoe -> Sweatshirts, Modern Pants (Confidence: 0.64)\n",
      "Sweatshirts -> Modern Pants, Running Shoe (Confidence: 0.69)\n",
      "Modern Pants, Running Shoe -> Sweatshirts (Confidence: 1.00)\n",
      "Modern Pants, Sweatshirts -> Running Shoe (Confidence: 0.90)\n",
      "Running Shoe, Sweatshirts -> Modern Pants (Confidence: 0.82)\n",
      "Modern Pants -> Sweatshirts, Socks (Confidence: 0.90)\n",
      "Socks -> Sweatshirts, Modern Pants (Confidence: 0.69)\n",
      "Sweatshirts -> Modern Pants, Socks (Confidence: 0.69)\n",
      "Modern Pants, Socks -> Sweatshirts (Confidence: 1.00)\n",
      "Modern Pants, Sweatshirts -> Socks (Confidence: 0.90)\n",
      "Socks, Sweatshirts -> Modern Pants (Confidence: 0.75)\n",
      "Running Shoe -> Sweatshirts, Socks (Confidence: 0.71)\n",
      "Socks -> Sweatshirts, Running Shoe (Confidence: 0.77)\n",
      "Sweatshirts -> Socks, Running Shoe (Confidence: 0.77)\n",
      "Running Shoe, Socks -> Sweatshirts (Confidence: 0.91)\n",
      "Running Shoe, Sweatshirts -> Socks (Confidence: 0.91)\n",
      "Socks, Sweatshirts -> Running Shoe (Confidence: 0.83)\n",
      "Modern Pants -> Sweatshirts, Socks, Running Shoe (Confidence: 0.80)\n",
      "Running Shoe -> Sweatshirts, Modern Pants, Socks (Confidence: 0.57)\n",
      "Socks -> Sweatshirts, Modern Pants, Running Shoe (Confidence: 0.62)\n",
      "Sweatshirts -> Modern Pants, Socks, Running Shoe (Confidence: 0.62)\n",
      "Modern Pants, Running Shoe -> Sweatshirts, Socks (Confidence: 0.89)\n",
      "Modern Pants, Socks -> Sweatshirts, Running Shoe (Confidence: 0.89)\n",
      "Modern Pants, Sweatshirts -> Socks, Running Shoe (Confidence: 0.80)\n",
      "Running Shoe, Socks -> Sweatshirts, Modern Pants (Confidence: 0.73)\n",
      "Running Shoe, Sweatshirts -> Modern Pants, Socks (Confidence: 0.73)\n",
      "Socks, Sweatshirts -> Modern Pants, Running Shoe (Confidence: 0.67)\n",
      "Modern Pants, Running Shoe, Socks -> Sweatshirts (Confidence: 1.00)\n",
      "Modern Pants, Running Shoe, Sweatshirts -> Socks (Confidence: 0.89)\n",
      "Modern Pants, Socks, Sweatshirts -> Running Shoe (Confidence: 0.89)\n",
      "Running Shoe, Socks, Sweatshirts -> Modern Pants (Confidence: 0.80)\n",
      "Runtime: 0.0131 seconds\n",
      "\n",
      "Running MLxtend Apriori Algorithm...\n",
      "\n",
      "MLXTEND APRIORI\n",
      "\n",
      "Dry Fit V-Nick | Support: 0.45\n",
      "Hoodies | Support: 0.40\n",
      "Modern Pants | Support: 0.50\n",
      "Rash Guard | Support: 0.60\n",
      "Running Shoe | Support: 0.70\n",
      "Socks | Support: 0.65\n",
      "Sweatshirts | Support: 0.65\n",
      "Swimming Shirt | Support: 0.55\n",
      "Tech Pants | Support: 0.45\n",
      "Dry Fit V-Nick, Rash Guard | Support: 0.45\n",
      "Swimming Shirt, Dry Fit V-Nick | Support: 0.40\n",
      "Dry Fit V-Nick, Tech Pants | Support: 0.40\n",
      "Rash Guard, Hoodies | Support: 0.40\n",
      "Tech Pants, Hoodies | Support: 0.40\n",
      "Modern Pants, Running Shoe | Support: 0.45\n",
      "Modern Pants, Socks | Support: 0.45\n",
      "Sweatshirts, Modern Pants | Support: 0.50\n",
      "Swimming Shirt, Rash Guard | Support: 0.50\n",
      "Tech Pants, Rash Guard | Support: 0.45\n",
      "Socks, Running Shoe | Support: 0.55\n",
      "Sweatshirts, Running Shoe | Support: 0.55\n",
      "Sweatshirts, Socks | Support: 0.60\n",
      "Swimming Shirt, Dry Fit V-Nick, Rash Guard | Support: 0.40\n",
      "Dry Fit V-Nick, Tech Pants, Rash Guard | Support: 0.40\n",
      "Rash Guard, Tech Pants, Hoodies | Support: 0.40\n",
      "Modern Pants, Socks, Running Shoe | Support: 0.40\n",
      "Sweatshirts, Modern Pants, Running Shoe | Support: 0.45\n",
      "Sweatshirts, Modern Pants, Socks | Support: 0.45\n",
      "Sweatshirts, Socks, Running Shoe | Support: 0.50\n",
      "Sweatshirts, Modern Pants, Socks, Running Shoe | Support: 0.40\n",
      "\n",
      "Association Rules:\n",
      "Dry Fit V-Nick -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Dry Fit V-Nick (Confidence: 0.75)\n",
      "Swimming Shirt -> Dry Fit V-Nick (Confidence: 0.73)\n",
      "Dry Fit V-Nick -> Swimming Shirt (Confidence: 0.89)\n",
      "Dry Fit V-Nick -> Tech Pants (Confidence: 0.89)\n",
      "Tech Pants -> Dry Fit V-Nick (Confidence: 0.89)\n",
      "Rash Guard -> Hoodies (Confidence: 0.67)\n",
      "Hoodies -> Rash Guard (Confidence: 1.00)\n",
      "Tech Pants -> Hoodies (Confidence: 0.89)\n",
      "Hoodies -> Tech Pants (Confidence: 1.00)\n",
      "Modern Pants -> Running Shoe (Confidence: 0.90)\n",
      "Running Shoe -> Modern Pants (Confidence: 0.64)\n",
      "Modern Pants -> Socks (Confidence: 0.90)\n",
      "Socks -> Modern Pants (Confidence: 0.69)\n",
      "Sweatshirts -> Modern Pants (Confidence: 0.77)\n",
      "Modern Pants -> Sweatshirts (Confidence: 1.00)\n",
      "Swimming Shirt -> Rash Guard (Confidence: 0.91)\n",
      "Rash Guard -> Swimming Shirt (Confidence: 0.83)\n",
      "Tech Pants -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Tech Pants (Confidence: 0.75)\n",
      "Socks -> Running Shoe (Confidence: 0.85)\n",
      "Running Shoe -> Socks (Confidence: 0.79)\n",
      "Sweatshirts -> Running Shoe (Confidence: 0.85)\n",
      "Running Shoe -> Sweatshirts (Confidence: 0.79)\n",
      "Sweatshirts -> Socks (Confidence: 0.92)\n",
      "Socks -> Sweatshirts (Confidence: 0.92)\n",
      "Swimming Shirt, Dry Fit V-Nick -> Rash Guard (Confidence: 1.00)\n",
      "Swimming Shirt, Rash Guard -> Dry Fit V-Nick (Confidence: 0.80)\n",
      "Dry Fit V-Nick, Rash Guard -> Swimming Shirt (Confidence: 0.89)\n",
      "Swimming Shirt -> Dry Fit V-Nick, Rash Guard (Confidence: 0.73)\n",
      "Dry Fit V-Nick -> Swimming Shirt, Rash Guard (Confidence: 0.89)\n",
      "Rash Guard -> Swimming Shirt, Dry Fit V-Nick (Confidence: 0.67)\n",
      "Dry Fit V-Nick, Tech Pants -> Rash Guard (Confidence: 1.00)\n",
      "Dry Fit V-Nick, Rash Guard -> Tech Pants (Confidence: 0.89)\n",
      "Tech Pants, Rash Guard -> Dry Fit V-Nick (Confidence: 0.89)\n",
      "Dry Fit V-Nick -> Tech Pants, Rash Guard (Confidence: 0.89)\n",
      "Tech Pants -> Dry Fit V-Nick, Rash Guard (Confidence: 0.89)\n",
      "Rash Guard -> Dry Fit V-Nick, Tech Pants (Confidence: 0.67)\n",
      "Tech Pants, Rash Guard -> Hoodies (Confidence: 0.89)\n",
      "Hoodies, Rash Guard -> Tech Pants (Confidence: 1.00)\n",
      "Tech Pants, Hoodies -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Tech Pants, Hoodies (Confidence: 0.67)\n",
      "Tech Pants -> Hoodies, Rash Guard (Confidence: 0.89)\n",
      "Hoodies -> Tech Pants, Rash Guard (Confidence: 1.00)\n",
      "Modern Pants, Socks -> Running Shoe (Confidence: 0.89)\n",
      "Modern Pants, Running Shoe -> Socks (Confidence: 0.89)\n",
      "Socks, Running Shoe -> Modern Pants (Confidence: 0.73)\n",
      "Modern Pants -> Socks, Running Shoe (Confidence: 0.80)\n",
      "Socks -> Modern Pants, Running Shoe (Confidence: 0.62)\n",
      "Running Shoe -> Modern Pants, Socks (Confidence: 0.57)\n",
      "Sweatshirts, Modern Pants -> Running Shoe (Confidence: 0.90)\n",
      "Sweatshirts, Running Shoe -> Modern Pants (Confidence: 0.82)\n",
      "Modern Pants, Running Shoe -> Sweatshirts (Confidence: 1.00)\n",
      "Sweatshirts -> Modern Pants, Running Shoe (Confidence: 0.69)\n",
      "Modern Pants -> Sweatshirts, Running Shoe (Confidence: 0.90)\n",
      "Running Shoe -> Sweatshirts, Modern Pants (Confidence: 0.64)\n",
      "Sweatshirts, Modern Pants -> Socks (Confidence: 0.90)\n",
      "Sweatshirts, Socks -> Modern Pants (Confidence: 0.75)\n",
      "Modern Pants, Socks -> Sweatshirts (Confidence: 1.00)\n",
      "Sweatshirts -> Modern Pants, Socks (Confidence: 0.69)\n",
      "Modern Pants -> Sweatshirts, Socks (Confidence: 0.90)\n",
      "Socks -> Sweatshirts, Modern Pants (Confidence: 0.69)\n",
      "Sweatshirts, Socks -> Running Shoe (Confidence: 0.83)\n",
      "Sweatshirts, Running Shoe -> Socks (Confidence: 0.91)\n",
      "Socks, Running Shoe -> Sweatshirts (Confidence: 0.91)\n",
      "Sweatshirts -> Socks, Running Shoe (Confidence: 0.77)\n",
      "Socks -> Sweatshirts, Running Shoe (Confidence: 0.77)\n",
      "Running Shoe -> Sweatshirts, Socks (Confidence: 0.71)\n",
      "Sweatshirts, Modern Pants, Socks -> Running Shoe (Confidence: 0.89)\n",
      "Sweatshirts, Modern Pants, Running Shoe -> Socks (Confidence: 0.89)\n",
      "Sweatshirts, Socks, Running Shoe -> Modern Pants (Confidence: 0.80)\n",
      "Modern Pants, Socks, Running Shoe -> Sweatshirts (Confidence: 1.00)\n",
      "Sweatshirts, Modern Pants -> Socks, Running Shoe (Confidence: 0.80)\n",
      "Sweatshirts, Socks -> Modern Pants, Running Shoe (Confidence: 0.67)\n",
      "Sweatshirts, Running Shoe -> Modern Pants, Socks (Confidence: 0.73)\n",
      "Modern Pants, Socks -> Sweatshirts, Running Shoe (Confidence: 0.89)\n",
      "Modern Pants, Running Shoe -> Sweatshirts, Socks (Confidence: 0.89)\n",
      "Socks, Running Shoe -> Sweatshirts, Modern Pants (Confidence: 0.73)\n",
      "Sweatshirts -> Modern Pants, Socks, Running Shoe (Confidence: 0.62)\n",
      "Modern Pants -> Sweatshirts, Socks, Running Shoe (Confidence: 0.80)\n",
      "Socks -> Sweatshirts, Modern Pants, Running Shoe (Confidence: 0.62)\n",
      "Running Shoe -> Sweatshirts, Modern Pants, Socks (Confidence: 0.57)\n",
      "Runtime: 0.0163 seconds\n",
      "\n",
      "Running FP-Growth Algorithm...\n",
      "\n",
      "FP-GROWTH\n",
      "\n",
      "Running Shoe | Support: 0.70\n",
      "Socks | Support: 0.65\n",
      "Sweatshirts | Support: 0.65\n",
      "Modern Pants | Support: 0.50\n",
      "Rash Guard | Support: 0.60\n",
      "Tech Pants | Support: 0.45\n",
      "Hoodies | Support: 0.40\n",
      "Swimming Shirt | Support: 0.55\n",
      "Dry Fit V-Nick | Support: 0.45\n",
      "Socks, Running Shoe | Support: 0.55\n",
      "Sweatshirts, Socks | Support: 0.60\n",
      "Sweatshirts, Running Shoe | Support: 0.55\n",
      "Sweatshirts, Socks, Running Shoe | Support: 0.50\n",
      "Sweatshirts, Modern Pants | Support: 0.50\n",
      "Modern Pants, Socks | Support: 0.45\n",
      "Modern Pants, Running Shoe | Support: 0.45\n",
      "Sweatshirts, Modern Pants, Socks | Support: 0.45\n",
      "Sweatshirts, Modern Pants, Running Shoe | Support: 0.45\n",
      "Modern Pants, Socks, Running Shoe | Support: 0.40\n",
      "Sweatshirts, Modern Pants, Socks, Running Shoe | Support: 0.40\n",
      "Tech Pants, Rash Guard | Support: 0.45\n",
      "Tech Pants, Hoodies | Support: 0.40\n",
      "Rash Guard, Hoodies | Support: 0.40\n",
      "Rash Guard, Tech Pants, Hoodies | Support: 0.40\n",
      "Swimming Shirt, Rash Guard | Support: 0.50\n",
      "Dry Fit V-Nick, Rash Guard | Support: 0.45\n",
      "Dry Fit V-Nick, Tech Pants | Support: 0.40\n",
      "Swimming Shirt, Dry Fit V-Nick | Support: 0.40\n",
      "Dry Fit V-Nick, Tech Pants, Rash Guard | Support: 0.40\n",
      "Swimming Shirt, Dry Fit V-Nick, Rash Guard | Support: 0.40\n",
      "\n",
      "Association Rules:\n",
      "Socks -> Running Shoe (Confidence: 0.85)\n",
      "Running Shoe -> Socks (Confidence: 0.79)\n",
      "Sweatshirts -> Socks (Confidence: 0.92)\n",
      "Socks -> Sweatshirts (Confidence: 0.92)\n",
      "Sweatshirts -> Running Shoe (Confidence: 0.85)\n",
      "Running Shoe -> Sweatshirts (Confidence: 0.79)\n",
      "Sweatshirts, Socks -> Running Shoe (Confidence: 0.83)\n",
      "Sweatshirts, Running Shoe -> Socks (Confidence: 0.91)\n",
      "Socks, Running Shoe -> Sweatshirts (Confidence: 0.91)\n",
      "Sweatshirts -> Socks, Running Shoe (Confidence: 0.77)\n",
      "Socks -> Sweatshirts, Running Shoe (Confidence: 0.77)\n",
      "Running Shoe -> Sweatshirts, Socks (Confidence: 0.71)\n",
      "Sweatshirts -> Modern Pants (Confidence: 0.77)\n",
      "Modern Pants -> Sweatshirts (Confidence: 1.00)\n",
      "Modern Pants -> Socks (Confidence: 0.90)\n",
      "Socks -> Modern Pants (Confidence: 0.69)\n",
      "Modern Pants -> Running Shoe (Confidence: 0.90)\n",
      "Running Shoe -> Modern Pants (Confidence: 0.64)\n",
      "Sweatshirts, Modern Pants -> Socks (Confidence: 0.90)\n",
      "Sweatshirts, Socks -> Modern Pants (Confidence: 0.75)\n",
      "Modern Pants, Socks -> Sweatshirts (Confidence: 1.00)\n",
      "Sweatshirts -> Modern Pants, Socks (Confidence: 0.69)\n",
      "Modern Pants -> Sweatshirts, Socks (Confidence: 0.90)\n",
      "Socks -> Sweatshirts, Modern Pants (Confidence: 0.69)\n",
      "Sweatshirts, Modern Pants -> Running Shoe (Confidence: 0.90)\n",
      "Sweatshirts, Running Shoe -> Modern Pants (Confidence: 0.82)\n",
      "Modern Pants, Running Shoe -> Sweatshirts (Confidence: 1.00)\n",
      "Sweatshirts -> Modern Pants, Running Shoe (Confidence: 0.69)\n",
      "Modern Pants -> Sweatshirts, Running Shoe (Confidence: 0.90)\n",
      "Running Shoe -> Sweatshirts, Modern Pants (Confidence: 0.64)\n",
      "Modern Pants, Socks -> Running Shoe (Confidence: 0.89)\n",
      "Modern Pants, Running Shoe -> Socks (Confidence: 0.89)\n",
      "Socks, Running Shoe -> Modern Pants (Confidence: 0.73)\n",
      "Modern Pants -> Socks, Running Shoe (Confidence: 0.80)\n",
      "Socks -> Modern Pants, Running Shoe (Confidence: 0.62)\n",
      "Running Shoe -> Modern Pants, Socks (Confidence: 0.57)\n",
      "Sweatshirts, Modern Pants, Socks -> Running Shoe (Confidence: 0.89)\n",
      "Sweatshirts, Modern Pants, Running Shoe -> Socks (Confidence: 0.89)\n",
      "Sweatshirts, Socks, Running Shoe -> Modern Pants (Confidence: 0.80)\n",
      "Modern Pants, Socks, Running Shoe -> Sweatshirts (Confidence: 1.00)\n",
      "Sweatshirts, Modern Pants -> Socks, Running Shoe (Confidence: 0.80)\n",
      "Sweatshirts, Socks -> Modern Pants, Running Shoe (Confidence: 0.67)\n",
      "Sweatshirts, Running Shoe -> Modern Pants, Socks (Confidence: 0.73)\n",
      "Modern Pants, Socks -> Sweatshirts, Running Shoe (Confidence: 0.89)\n",
      "Modern Pants, Running Shoe -> Sweatshirts, Socks (Confidence: 0.89)\n",
      "Socks, Running Shoe -> Sweatshirts, Modern Pants (Confidence: 0.73)\n",
      "Sweatshirts -> Modern Pants, Socks, Running Shoe (Confidence: 0.62)\n",
      "Modern Pants -> Sweatshirts, Socks, Running Shoe (Confidence: 0.80)\n",
      "Socks -> Sweatshirts, Modern Pants, Running Shoe (Confidence: 0.62)\n",
      "Running Shoe -> Sweatshirts, Modern Pants, Socks (Confidence: 0.57)\n",
      "Tech Pants -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Tech Pants (Confidence: 0.75)\n",
      "Tech Pants -> Hoodies (Confidence: 0.89)\n",
      "Hoodies -> Tech Pants (Confidence: 1.00)\n",
      "Rash Guard -> Hoodies (Confidence: 0.67)\n",
      "Hoodies -> Rash Guard (Confidence: 1.00)\n",
      "Tech Pants, Rash Guard -> Hoodies (Confidence: 0.89)\n",
      "Hoodies, Rash Guard -> Tech Pants (Confidence: 1.00)\n",
      "Tech Pants, Hoodies -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Tech Pants, Hoodies (Confidence: 0.67)\n",
      "Tech Pants -> Hoodies, Rash Guard (Confidence: 0.89)\n",
      "Hoodies -> Tech Pants, Rash Guard (Confidence: 1.00)\n",
      "Swimming Shirt -> Rash Guard (Confidence: 0.91)\n",
      "Rash Guard -> Swimming Shirt (Confidence: 0.83)\n",
      "Dry Fit V-Nick -> Rash Guard (Confidence: 1.00)\n",
      "Rash Guard -> Dry Fit V-Nick (Confidence: 0.75)\n",
      "Dry Fit V-Nick -> Tech Pants (Confidence: 0.89)\n",
      "Tech Pants -> Dry Fit V-Nick (Confidence: 0.89)\n",
      "Swimming Shirt -> Dry Fit V-Nick (Confidence: 0.73)\n",
      "Dry Fit V-Nick -> Swimming Shirt (Confidence: 0.89)\n",
      "Dry Fit V-Nick, Tech Pants -> Rash Guard (Confidence: 1.00)\n",
      "Dry Fit V-Nick, Rash Guard -> Tech Pants (Confidence: 0.89)\n",
      "Tech Pants, Rash Guard -> Dry Fit V-Nick (Confidence: 0.89)\n",
      "Dry Fit V-Nick -> Tech Pants, Rash Guard (Confidence: 0.89)\n",
      "Tech Pants -> Dry Fit V-Nick, Rash Guard (Confidence: 0.89)\n",
      "Rash Guard -> Dry Fit V-Nick, Tech Pants (Confidence: 0.67)\n",
      "Swimming Shirt, Dry Fit V-Nick -> Rash Guard (Confidence: 1.00)\n",
      "Swimming Shirt, Rash Guard -> Dry Fit V-Nick (Confidence: 0.80)\n",
      "Dry Fit V-Nick, Rash Guard -> Swimming Shirt (Confidence: 0.89)\n",
      "Swimming Shirt -> Dry Fit V-Nick, Rash Guard (Confidence: 0.73)\n",
      "Dry Fit V-Nick -> Swimming Shirt, Rash Guard (Confidence: 0.89)\n",
      "Rash Guard -> Swimming Shirt, Dry Fit V-Nick (Confidence: 0.67)\n",
      "Runtime: 0.0246 seconds\n",
      "TIMING COMPARISON\n",
      "\n",
      "Algorithm            | Execution Time (s)\n",
      "----------------------------------------\n",
      "Brute Force          | 0.0131            \n",
      "Apriori              | 0.0163            \n",
      "FP-Growth            | 0.0246            \n",
      "\n",
      "Analysis completed successfully!\n",
      "All three algorithms have been executed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Optional, Set, Any, Union\n",
    "\n",
    "# Resolve project directories independent of current working directory\n",
    "try:\n",
    "    __file__  # will NameError in notebooks\n",
    "    _IN_NOTEBOOK = False\n",
    "except NameError:\n",
    "    _IN_NOTEBOOK = True\n",
    "from pathlib import Path as _Path\n",
    "if _IN_NOTEBOOK:\n",
    "    # Prefer a local ./data folder next to this notebook\n",
    "    _candidates = [\n",
    "        _Path.cwd() / 'data',\n",
    "        _Path.cwd() / 'Data',\n",
    "        _Path.cwd().parent / 'data',\n",
    "        _Path.cwd().parent / 'Data',\n",
    "    ]\n",
    "    for _c in _candidates:\n",
    "        if _c.exists():\n",
    "            DATA_DIR = str(_c.resolve())\n",
    "            break\n",
    "    else:\n",
    "        DATA_DIR = str((_Path.cwd() / 'data').resolve())\n",
    "        os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    BASE_DIR = str(_Path.cwd())\n",
    "    PROJECT_ROOT = str(_Path.cwd())\n",
    "else:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "    PROJECT_ROOT = os.path.abspath(os.path.join(BASE_DIR, os.pardir))\n",
    "    DATA_DIR = os.path.join(PROJECT_ROOT, 'Data')\n",
    "\n",
    "\n",
    "#   PERFORMANCE & UTILITY HELPERS\n",
    "\n",
    "def _clean_item(value: Any) -> str:\n",
    "    \"\"\"Return an ASCII-friendly string representation of an item.\"\"\"\n",
    "    if value is None:\n",
    "        return \"\"\n",
    "\n",
    "    s = str(value)\n",
    "    replacements = {\n",
    "        \"\\u2019\": \"'\",\n",
    "        \"\\u2018\": \"'\",\n",
    "        \"\\u201c\": '\"',\n",
    "        \"\\u201d\": '\"',\n",
    "        \"\\u2013\": '-',\n",
    "        \"\\u2014\": '-',\n",
    "        \"\\u00a0\": ' ',\n",
    "    }\n",
    "    for bad, good in replacements.items():\n",
    "        s = s.replace(bad, good)\n",
    "\n",
    "    # Collapse consecutive whitespace\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def _format_itemset_display(itemset: Union[Tuple[str, ...], List[str], Set[str], str]) -> str:\n",
    "    \"\"\"Format an itemset for display using comma-separated ASCII strings.\"\"\"\n",
    "    if isinstance(itemset, (list, tuple, set)):\n",
    "        items = [_clean_item(item) for item in itemset]\n",
    "        return \", \".join(items)\n",
    "    return _clean_item(itemset)\n",
    "\n",
    "def memory_efficient_itemset_generator(items: List[str], size: int):\n",
    "    \n",
    "    from itertools import combinations\n",
    "    for itemset in combinations(items, size):\n",
    "        yield itemset\n",
    "\n",
    "def validate_transaction_format(transactions: List[List[str]]) -> bool:\n",
    "    \n",
    "    if not isinstance(transactions, list):\n",
    "        return False\n",
    "    \n",
    "    for transaction in transactions:\n",
    "        if not isinstance(transaction, list):\n",
    "            return False\n",
    "        for item in transaction:\n",
    "            if not isinstance(item, str):\n",
    "                return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "#       CONSTANTS & CONFIG\n",
    "\n",
    "class Config:\n",
    "\n",
    "    PROJECT_ROOT = PROJECT_ROOT\n",
    "    DATA_DIR = DATA_DIR\n",
    "\n",
    "    # Dataset configuration\n",
    "    DATASETS = {\n",
    "        1: \"Amazon_Transactions.csv\",\n",
    "        2: \"BestBuy_Transactions.csv\", \n",
    "        3: \"KMart_Transactions.csv\",\n",
    "        4: \"Custom_Transactions.csv\",\n",
    "        5: \"Nike_Transactions.csv\",\n",
    "    }\n",
    "    \n",
    "    DATASET_DESCRIPTIONS = {\n",
    "        1: \"Amazon_Transactions.csv\",\n",
    "        2: \"BestBuy_Transactions.csv\",\n",
    "        3: \"KMart_Transactions.csv\", \n",
    "        4: \"Custom_Transactions.csv\",\n",
    "        5: \"Nike_Transactions.csv\"\n",
    "    }\n",
    "    \n",
    "    # Column names\n",
    "    TRANSACTION_COLUMN = 'Transaction'\n",
    "    TRANSACTION_ID_COLUMN = 'Transaction ID'\n",
    "    \n",
    "    # Validation constants\n",
    "    MIN_SUPPORT_RANGE = (0.0, 1.0)\n",
    "    MIN_CONFIDENCE_RANGE = (0.0, 1.0)\n",
    "    VALID_DATASET_CHOICES = (1, 5)\n",
    "    MAX_INPUT_LENGTH = 1\n",
    "    \n",
    "    # Display formatting\n",
    "    DECIMAL_PRECISION = 2\n",
    "    TIME_PRECISION = 4\n",
    "    \n",
    "    # Algorithm names\n",
    "    BRUTE_FORCE_NAME = \"BRUTE-FORCE APRIORI\"\n",
    "    MLXTEND_APRIORI_NAME = \"MLXTEND APRIORI\" \n",
    "    FP_GROWTH_NAME = \"FP-GROWTH\"\n",
    "    \n",
    "    # Timing comparison\n",
    "    TIMING_TABLE_WIDTH = 40\n",
    "    ALGORITHM_COL_WIDTH = 20\n",
    "    TIME_COL_WIDTH = 18\n",
    "    \n",
    "    # Warning thresholds\n",
    "    ZERO_SUPPORT_WARNING = True\n",
    "    ZERO_CONFIDENCE_WARNING = True\n",
    "\n",
    "#     DATASET LOADING\n",
    "\n",
    "def load_transaction_dataset(choice: int) -> Optional[pd.DataFrame]:\n",
    "\n",
    "    try:\n",
    "        file_name = Config.DATASETS.get(choice)\n",
    "        if not file_name:\n",
    "            raise ValueError(f\"Invalid choice: {choice}. Please select between {Config.VALID_DATASET_CHOICES[0]} and {Config.VALID_DATASET_CHOICES[1]}.\")\n",
    "        file_path = os.path.join(Config.DATA_DIR, file_name)\n",
    "\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Dataset file '{file_name}' not found in '{Config.DATA_DIR}'.\")\n",
    "        \n",
    "        # Load dataset with validation\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Validate dataset structure\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"Dataset '{file_path}' is empty.\")\n",
    "        \n",
    "        if Config.TRANSACTION_COLUMN not in df.columns:\n",
    "            raise ValueError(f\"Dataset '{file_path}' missing required '{Config.TRANSACTION_COLUMN}' column.\")\n",
    "        \n",
    "        # Check for null values in Transaction column\n",
    "        null_count = df[Config.TRANSACTION_COLUMN].isnull().sum()\n",
    "        if null_count > 0:\n",
    "            print(f\"Warning: Found {null_count} null transactions. These will be removed.\")\n",
    "            df = df.dropna(subset=[Config.TRANSACTION_COLUMN])\n",
    "\n",
    "        print(f\"Successfully loaded dataset: {file_name}\")\n",
    "        print(f\"Dataset contains {len(df)} transactions\")\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File Error: {e}\")\n",
    "        print(f\"Please ensure all dataset files are located in '{Config.DATA_DIR}'.\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: Dataset '{file_path}' is empty or corrupted.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Parse Error: Unable to read '{file_path}' - {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "#   BRUTE-FORCE\n",
    "\n",
    "def brute_force(transactions: List[List[str]], min_support: float, min_confidence: float) -> Tuple[List[Tuple], List[int], List[Tuple]]:\n",
    "    \n",
    "    # Convert transactions to sets for faster subset operations\n",
    "    transaction_sets = [set(t) for t in transactions]\n",
    "    n_transactions = len(transactions)\n",
    "    \n",
    "    # Get all unique items and create 1-itemsets\n",
    "    unique_items = sorted(set(item for t in transactions for item in t))\n",
    "    \n",
    "    # Initialize with frequent 1-itemsets\n",
    "    current_frequent = []\n",
    "    frequent_patterns = []\n",
    "    pattern_counts = []\n",
    "    \n",
    "    # Find frequent 1-itemsets\n",
    "    item_counts = {}\n",
    "    for item in unique_items:\n",
    "        count = sum(1 for t in transaction_sets if item in t)\n",
    "        support = count / n_transactions\n",
    "        if support >= min_support:\n",
    "            current_frequent.append((item,))\n",
    "            frequent_patterns.append((item,))\n",
    "            pattern_counts.append(count)\n",
    "            item_counts[item] = count\n",
    "    \n",
    "    # Generate frequent k-itemsets using brute force pruning\n",
    "    k = 2\n",
    "    while current_frequent:\n",
    "        # Generate candidates using frequent (k-1)-itemsets\n",
    "        candidates = _generate_candidates(current_frequent, k)\n",
    "        new_frequent = []\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            # Pruning: check if all (k-1)-subsets are frequent\n",
    "            if _has_infrequent_subset(candidate, current_frequent):\n",
    "                continue\n",
    "                \n",
    "            # Count support for this candidate\n",
    "            count = sum(1 for t in transaction_sets if set(candidate).issubset(t))\n",
    "            support = count / n_transactions\n",
    "            \n",
    "            if support >= min_support:\n",
    "                new_frequent.append(candidate)\n",
    "                frequent_patterns.append(candidate)\n",
    "                pattern_counts.append(count)\n",
    "        \n",
    "        current_frequent = new_frequent\n",
    "        k += 1\n",
    "    \n",
    "    # Generate association rules\n",
    "    rules = _generate_optimized_rules(frequent_patterns, pattern_counts, transaction_sets, min_confidence)\n",
    "    return frequent_patterns, pattern_counts, rules\n",
    "\n",
    "def _generate_candidates(frequent_itemsets: List[Tuple], k: int) -> List[Tuple]:\n",
    "    \n",
    "    candidates = []\n",
    "    n = len(frequent_itemsets)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # Join two (k-1)-itemsets if they differ by only one item\n",
    "            set1, set2 = set(frequent_itemsets[i]), set(frequent_itemsets[j])\n",
    "            if len(set1.union(set2)) == k:\n",
    "                candidate = tuple(sorted(set1.union(set2)))\n",
    "                if candidate not in candidates:\n",
    "                    candidates.append(candidate)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def _has_infrequent_subset(candidate: Tuple, frequent_itemsets: List[Tuple]) -> bool:\n",
    "    \n",
    "    frequent_set = set(frequent_itemsets)\n",
    "    \n",
    "    # Check all (k-1)-subsets of the candidate\n",
    "    for i in range(len(candidate)):\n",
    "        subset = candidate[:i] + candidate[i+1:]\n",
    "        if subset not in frequent_set:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _generate_optimized_rules(frequent_patterns: List[Tuple], pattern_counts: List[int], \n",
    "                            transaction_sets: List[Set[str]], min_confidence: float) -> List[Tuple]:\n",
    "    \n",
    "    rules = []\n",
    "    \n",
    "    # Create a mapping for fast lookup of pattern counts\n",
    "    pattern_count_map = {pattern: count for pattern, count in zip(frequent_patterns, pattern_counts)}\n",
    "    \n",
    "    for pattern, count in zip(frequent_patterns, pattern_counts):\n",
    "        if len(pattern) <= 1:\n",
    "            continue\n",
    "            \n",
    "        # Generate all possible antecedents (non-empty proper subsets)\n",
    "        for i in range(1, len(pattern)):\n",
    "            for antecedent in combinations(pattern, i):\n",
    "                # Get antecedent count from our mapping (if available) or calculate\n",
    "                antecedent_count = pattern_count_map.get(antecedent)\n",
    "                if antecedent_count is None:\n",
    "                    antecedent_count = sum(1 for t in transaction_sets if set(antecedent).issubset(t))\n",
    "                \n",
    "                if antecedent_count == 0:\n",
    "                    continue\n",
    "                    \n",
    "                confidence = count / antecedent_count\n",
    "                if confidence >= min_confidence:\n",
    "                    consequent = tuple(set(pattern) - set(antecedent))\n",
    "                    rules.append((antecedent, consequent, confidence))\n",
    "    \n",
    "    return rules\n",
    "\n",
    "# Backward compatibility function\n",
    "def generate_rules(frequent_patterns: List[Tuple], pattern_counts: List[int], \n",
    "                  transactions: List[List[str]], min_confidence: float) -> List[Tuple]:\n",
    "    \n",
    "    transaction_sets = [set(t) for t in transactions]\n",
    "    return _generate_optimized_rules(frequent_patterns, pattern_counts, transaction_sets, min_confidence)\n",
    "\n",
    "def display_brute_force_results(patterns: List[Tuple], counts: List[int], \n",
    "                              transactions: List[List[str]], rules: List[Tuple], \n",
    "                              runtime: float) -> None:\n",
    "    \n",
    "    print(f\"\\n{Config.BRUTE_FORCE_NAME}\")\n",
    "    print()\n",
    "    \n",
    "    for pattern, count in zip(patterns, counts):\n",
    "        support = count / len(transactions)\n",
    "        item_str = _format_itemset_display(pattern)\n",
    "        print(f\"{item_str} | Support: {support:.{Config.DECIMAL_PRECISION}f}\")\n",
    "    \n",
    "    print(\"\\nAssociation Rules:\")\n",
    "    for antecedent, consequent, confidence in rules:\n",
    "        # Use ASCII arrow to avoid encoding issues on some consoles\n",
    "        antecedent_str = _format_itemset_display(antecedent)\n",
    "        consequent_str = _format_itemset_display(consequent)\n",
    "        print(f\"{antecedent_str} -> {consequent_str} (Confidence: {confidence:.{Config.DECIMAL_PRECISION}f})\")\n",
    "    \n",
    "    print(f\"Runtime: {runtime:.{Config.TIME_PRECISION}f} seconds\")\n",
    "\n",
    "#  MLXTEND ALGORITHM PIPELINES\n",
    "\n",
    "def _prepare_mlxtend_data(transactions: List[List[str]]) -> pd.DataFrame:\n",
    "    \n",
    "    te = TransactionEncoder()\n",
    "    return pd.DataFrame(te.fit(transactions).transform(transactions), columns=te.columns_)\n",
    "\n",
    "def _display_mlxtend_results(freq_items: pd.DataFrame, rules: pd.DataFrame, \n",
    "                           runtime: float, algorithm_name: str) -> None:\n",
    "    \n",
    "    print(f\"\\n{algorithm_name}\")\n",
    "    print()\n",
    "    \n",
    "    for _, row in freq_items.iterrows():\n",
    "        itemset_list = list(row['itemsets'])\n",
    "        support = row['support']\n",
    "        item_str = _format_itemset_display(itemset_list)\n",
    "        print(f\"{item_str} | Support: {support:.{Config.DECIMAL_PRECISION}f}\")\n",
    "    \n",
    "    print(\"\\nAssociation Rules:\")\n",
    "    for _, row in rules.iterrows():\n",
    "        antecedents = list(row['antecedents'])\n",
    "        consequents = list(row['consequents']) \n",
    "        confidence = row['confidence']\n",
    "        # Use ASCII arrow to avoid encoding issues on some consoles\n",
    "        antecedent_str = _format_itemset_display(antecedents)\n",
    "        consequent_str = _format_itemset_display(consequents)\n",
    "        print(f\"{antecedent_str} -> {consequent_str} (Confidence: {confidence:.{Config.DECIMAL_PRECISION}f})\")\n",
    "    \n",
    "    print(f\"Runtime: {runtime:.{Config.TIME_PRECISION}f} seconds\")\n",
    "\n",
    "def display_timing_comparison(brute_force_time: float, apriori_time: float, \n",
    "                            fp_growth_time: float) -> None:\n",
    "    \"\"\"Display a formatted timing comparison table for all algorithms.\"\"\"\n",
    "    \n",
    "    \n",
    "   \n",
    "    print(\"TIMING COMPARISON\")\n",
    "    print()\n",
    "\n",
    "    # Header\n",
    "    print(f\"{'Algorithm':<{Config.ALGORITHM_COL_WIDTH}} | {'Execution Time (s)':<{Config.TIME_COL_WIDTH}}\")\n",
    "    print(\"-\" * Config.TIMING_TABLE_WIDTH)\n",
    "\n",
    "    # Data rows (use configured time precision)\n",
    "    print(f\"{'Brute Force':<{Config.ALGORITHM_COL_WIDTH}} | {brute_force_time:<{Config.TIME_COL_WIDTH}.{Config.TIME_PRECISION}f}\")\n",
    "    print(f\"{'Apriori':<{Config.ALGORITHM_COL_WIDTH}} | {apriori_time:<{Config.TIME_COL_WIDTH}.{Config.TIME_PRECISION}f}\")\n",
    "    print(f\"{'FP-Growth':<{Config.ALGORITHM_COL_WIDTH}} | {fp_growth_time:<{Config.TIME_COL_WIDTH}.{Config.TIME_PRECISION}f}\")\n",
    "    print()\n",
    "\n",
    "def _run_mlxtend_algorithm(transactions: List[List[str]], min_support: float, \n",
    "                         min_confidence: float, algorithm_func: Any, \n",
    "                         algorithm_name: str) -> float:\n",
    "    \"\"\"Run MLxtend algorithm and return execution time.\"\"\"\n",
    "    \n",
    "    df_encoded = _prepare_mlxtend_data(transactions)\n",
    "    \n",
    "    start = time.time()\n",
    "    freq_items = algorithm_func(df_encoded, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(freq_items, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    end = time.time()\n",
    "    \n",
    "    runtime = end - start\n",
    "    _display_mlxtend_results(freq_items, rules, runtime, algorithm_name)\n",
    "    \n",
    "    return runtime\n",
    "\n",
    "#       APRIORI Method\n",
    "\n",
    "def run_apriori_mlxtend(transactions: List[List[str]], min_support: float, \n",
    "                       min_confidence: float) -> float:\n",
    "    \"\"\"Run MLxtend Apriori algorithm and return execution time.\"\"\"\n",
    "    \n",
    "    return _run_mlxtend_algorithm(transactions, min_support, min_confidence, \n",
    "                          apriori, Config.MLXTEND_APRIORI_NAME)\n",
    "\n",
    "#       FP-GROWTH METHOD\n",
    "\n",
    "def run_fp_growth(transactions: List[List[str]], min_support: float, \n",
    "                 min_confidence: float) -> float:\n",
    "    \"\"\"Run FP-Growth algorithm and return execution time.\"\"\"\n",
    "    \n",
    "    return _run_mlxtend_algorithm(transactions, min_support, min_confidence, \n",
    "                          fpgrowth, Config.FP_GROWTH_NAME)\n",
    "\n",
    "#    INPUT VALIDATION FUNCTIONS\n",
    "\n",
    "def get_valid_dataset_choice() -> Optional[int]:\n",
    "    \n",
    "    print(\"AVAILABLE DATASETS (from Create Data part):\")\n",
    "    print()\n",
    "    \n",
    "    for key, description in Config.DATASET_DESCRIPTIONS.items():\n",
    "        print(f\"{key}. {description}\")\n",
    "    print()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nEnter your dataset choice (1-5): \").strip()\n",
    "            \n",
    "            # Input validation - must be only 1 to enter\n",
    "            if len(user_input) != Config.MAX_INPUT_LENGTH:\n",
    "                print(f\"Error: Please enter only ONE digit ({Config.VALID_DATASET_CHOICES[0]}-{Config.VALID_DATASET_CHOICES[1]})\")\n",
    "                continue\n",
    "                \n",
    "            choice = int(user_input)\n",
    "            \n",
    "            if choice < Config.VALID_DATASET_CHOICES[0] or choice > Config.VALID_DATASET_CHOICES[1]:\n",
    "                print(f\"Error: Choice must be between {Config.VALID_DATASET_CHOICES[0]} and {Config.VALID_DATASET_CHOICES[1]}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Selected: {Config.DATASET_DESCRIPTIONS[choice]}\")\n",
    "            return choice\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Please enter a valid integer ({Config.VALID_DATASET_CHOICES[0]}-{Config.VALID_DATASET_CHOICES[1]})\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nProgram interrupted by user. Exiting...\")\n",
    "            return None\n",
    "\n",
    "def get_valid_support() -> Optional[float]:\n",
    "    \n",
    "    min_val, max_val = Config.MIN_SUPPORT_RANGE\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            support_input = input(f\"\\nEnter Minimum Support ({min_val} - {max_val}): \").strip()\n",
    "            \n",
    "            if not support_input:\n",
    "                print(\"Error: Support value cannot be empty\")\n",
    "                continue\n",
    "                \n",
    "            min_support = float(support_input)\n",
    "            \n",
    "            if min_support < min_val or min_support > max_val:\n",
    "                print(f\"Error: Support must be between {min_val} and {max_val}\")\n",
    "                continue\n",
    "                \n",
    "            if min_support == 0.0 and Config.ZERO_SUPPORT_WARNING:\n",
    "                print(\"Warning: Support of 0.0 may generate too many patterns\")\n",
    "                \n",
    "            print(f\"Minimum Support set to: {min_support}\")\n",
    "            return min_support\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(\"Error: Please enter a valid decimal number (e.g., 0.2, 0.5)\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nProgram interrupted by user. Exiting...\")\n",
    "            return None\n",
    "\n",
    "def get_valid_confidence() -> Optional[float]:\n",
    "    \n",
    "    min_val, max_val = Config.MIN_CONFIDENCE_RANGE\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            confidence_input = input(f\"Enter Minimum Confidence ({min_val} - {max_val}): \").strip()\n",
    "            \n",
    "            if not confidence_input:\n",
    "                print(\"Error: Confidence value cannot be empty\")\n",
    "                continue\n",
    "                \n",
    "            min_confidence = float(confidence_input)\n",
    "            \n",
    "            if min_confidence < min_val or min_confidence > max_val:\n",
    "                print(f\"Error: Confidence must be between {min_val} and {max_val}\")\n",
    "                continue\n",
    "                \n",
    "            if min_confidence == 0.0 and Config.ZERO_CONFIDENCE_WARNING:\n",
    "                print(\"Warning: Confidence of 0.0 may generate too many rules\")\n",
    "                \n",
    "            print(f\"Minimum Confidence set to: {min_confidence}\")\n",
    "            return min_confidence\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(\"Error: Please enter a valid decimal number (e.g., 0.6, 0.8)\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nProgram interrupted by user. Exiting...\")\n",
    "            return None\n",
    "\n",
    "#        MAIN EXECUTION\n",
    "\n",
    "def _process_transaction_data(df: pd.DataFrame) -> List[List[str]]:\n",
    "    \n",
    "    try:\n",
    "        # Process transaction column - split by commas and strip whitespace\n",
    "        df[Config.TRANSACTION_COLUMN] = df[Config.TRANSACTION_COLUMN].apply(\n",
    "            lambda x: [_clean_item(item.strip()) for item in str(x).split(',') if item.strip()]\n",
    "        )\n",
    "        \n",
    "        transactions = df[Config.TRANSACTION_COLUMN].tolist()\n",
    "        \n",
    "        # Validate processed transactions\n",
    "        if not transactions:\n",
    "            raise ValueError(\"No valid transactions found after processing\")\n",
    "        \n",
    "        # Remove empty transactions\n",
    "        transactions = [t for t in transactions if t and len(t) > 0]\n",
    "        \n",
    "        if not transactions:\n",
    "            raise ValueError(\"All transactions are empty after cleaning\")\n",
    "        \n",
    "        return transactions\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing transaction data: {e}\")\n",
    "\n",
    "def main() -> None:\n",
    "    \n",
    "    # Display program header\n",
    "    print(\"DATA MINING PROJECT\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Get valid dataset choice (single digit input required)\n",
    "        choice = get_valid_dataset_choice()\n",
    "        if choice is None:\n",
    "            return\n",
    "            \n",
    "        # Step 2: Load and validate selected dataset\n",
    "        df = load_transaction_dataset(choice)\n",
    "        if df is None:\n",
    "            print(\"Failed to load dataset. Program terminating.\")\n",
    "            return\n",
    "\n",
    "        # Step 3: Process transaction data with validation\n",
    "        print(\"\\nProcessing transaction data...\")\n",
    "        try:\n",
    "            transactions = _process_transaction_data(df)\n",
    "            print(f\"Successfully processed {len(transactions)} transactions\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return\n",
    "\n",
    "        # Step 4: Get user-specified parameters with validation\n",
    "        print(f\"\\nPARAMETER CONFIGURATION:\")\n",
    "        print()\n",
    "        \n",
    "        min_support = get_valid_support()\n",
    "        if min_support is None:\n",
    "            return\n",
    "            \n",
    "        min_confidence = get_valid_confidence()\n",
    "        if min_confidence is None:\n",
    "            return\n",
    "\n",
    "        # Step 5: Execute algorithms with performance monitoring\n",
    "        print(f\"\\nStarting analysis with Support={min_support}, Confidence={min_confidence}\")\n",
    "        print()\n",
    "\n",
    "        # Initialize timing variables\n",
    "        brute_force_time = 0.0\n",
    "        apriori_time = 0.0\n",
    "        fp_growth_time = 0.0\n",
    "\n",
    "        # Brute Force Apriori Algorithm\n",
    "        print(\"\\nRunning Brute-Force Apriori Algorithm...\")\n",
    "        try:\n",
    "            start = time.time()\n",
    "            patterns, counts, rules = brute_force(transactions, min_support, min_confidence)\n",
    "            end = time.time()\n",
    "            brute_force_time = end - start\n",
    "            display_brute_force_results(patterns, counts, transactions, rules, brute_force_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Brute-Force Apriori: {e}\")\n",
    "\n",
    "        # MLxtend Apriori Algorithm  \n",
    "        print(\"\\nRunning MLxtend Apriori Algorithm...\")\n",
    "        try:\n",
    "            apriori_time = run_apriori_mlxtend(transactions, min_support, min_confidence)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in MLxtend Apriori: {e}\")\n",
    "\n",
    "        # FP-Growth Algorithm\n",
    "        print(\"\\nRunning FP-Growth Algorithm...\")\n",
    "        try:\n",
    "            fp_growth_time = run_fp_growth(transactions, min_support, min_confidence)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in FP-Growth: {e}\")\n",
    "        \n",
    "        # Display timing comparison\n",
    "        if brute_force_time > 0 and apriori_time > 0 and fp_growth_time > 0:\n",
    "            display_timing_comparison(brute_force_time, apriori_time, fp_growth_time)\n",
    "        \n",
    "        # Success summary\n",
    "        print(\"Analysis completed successfully!\")\n",
    "        print(\"All three algorithms have been executed.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nProgram interrupted by user. Exiting gracefully...\")\n",
    "        print(\"Thank you for using the Market Basket Analysis tool!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nUnexpected error occurred: {e}\")\n",
    "        print(\"Please check your input and try again.\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4efd8c-669e-4548-861f-f9b6b8d980eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
